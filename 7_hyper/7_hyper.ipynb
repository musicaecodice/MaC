{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9dde309",
   "metadata": {},
   "source": [
    "[INDEX](../indice.ipynb) \n",
    "\n",
    "* [Framework and historical context](#histo5)\n",
    "    - [Sound and formal augmentation](#formal) \n",
    "    - [Augmentation of acoustic instruments](#hyper) \n",
    "    - [Common topics to think about](#commontopics) \n",
    "* [Software model](#smodels) \n",
    "    - [Bus and Groups](#groups) \n",
    "* [Feature extraction as control signals](#feature) \n",
    "    - [Envelope follower](#envfollow) \n",
    "    - [Pitch follower](#pifollow) \n",
    "    - [Centroid](#centroid) \n",
    "* [Classic live electronics sound processing](#classic)\n",
    "    - [Ring modulation](#rmod)\n",
    "    - [Live recording and playback](#lrec)\n",
    "    - [Granular synthesis](#grain)\n",
    "    - [Delay lines](#delay)\n",
    "* [Composition sketches proposal](#esercizi_5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc91be7-65df-4fa0-9fc7-ff4e6c5d2538",
   "metadata": {},
   "source": [
    "# Framework and historical context <a id=\"histo5\"></a>\n",
    "\n",
    "Mixed music combines acoustic instruments and electronic elements.\n",
    "\n",
    "Two different musical contexts:\n",
    "\n",
    "1. sound and formal augmentation (live composing).\n",
    "2. acoustic instruments augmentation (hyper-instruments).\n",
    "\n",
    "For both of them we can do it in two ways:\n",
    "\n",
    "* superimposing pre-composed electronic sounds and acoustic instruments.\n",
    "* acoustic instruments real-time sound processing.\n",
    "\n",
    "For both we have usually:\n",
    "- one electronic performer.\n",
    "- one sound director.\n",
    "- one or more instrumental performers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aa25a4",
   "metadata": {},
   "source": [
    "## Sound and formal augmentation <a id=\"formal\"></a>\n",
    "\n",
    "In this context we can:\n",
    "\n",
    "1. design a chamber music work for one or more acoustic instruments whose sounds develop immersed in a sound background created by electronics (virtual orchestration and scoring).\n",
    "\n",
    "   Dai Fujikura, Prism spectra (2007) for viola and live electronics - extract.\n",
    "\n",
    "   <audio controls src='suoni/fuji.mp3'></audio>\n",
    "\n",
    "    If we want to do it with pre-composed electronic sounds (soundfiles) there are different configurations:\n",
    "    - fixed electronic sounds - fixed intrumental part.\n",
    "    - fixed electronic sounds - improvised instrumental part.\n",
    "    - improvised electronics - fixed intrumental part.\n",
    "    - improvised electronics - improvised instrumental part.\n",
    "\n",
    "    The technical implementation for this mode is explained in the \"Live playback and synthesis\" paragraph of the previous chapter.\n",
    "\n",
    "    If we want to do it in real-time the main sound processing techniques are:\n",
    "    - accumulation of musical materials $\\rightarrow$ delay lines with or without feedback and/or transpositions.\n",
    "    - iteration of rhythmic-melodic patterns $\\rightarrow$ loop machines and live recording-playback systems.\n",
    "    - freeze sounds $\\rightarrow$ create fixed or continuously evolving harmonic fields-sound backgrounds.\n",
    "\n",
    "    The technical implementations are presented in a dedicated paragraph in this chapter.\n",
    "\n",
    "2. change the perception of a place by modifying its acoustic characteristics:\n",
    "  - within a composition.\n",
    "\n",
    "     Luigi Nono - \"A Pierre. Dell'Azzurro Silenzio, Inquietum\" (1985) for doublebass flute, doublebass clarinet and live electronics - extract.\n",
    "\n",
    "     <audio controls src='suoni/nono.mp3'></audio>\n",
    "  - in the creation of a sound art installation.\n",
    "\n",
    "    David Tudor, Rainforest (1973) - extract.\n",
    "    <center><video width=\"40%\" controls src=\"suoni/rainforest1.mp4\"></video></center>\n",
    "\n",
    "    Here the focus is on type of sound diffusion systems.\n",
    "\n",
    "    We talk about this topic in the \"Common topics\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ea6ae3",
   "metadata": {},
   "source": [
    "## Augmentation of acoustic instruments <a id=\"hyper\"></a>\n",
    "\n",
    "Hyper-instruments are based on the goal of designing expanded musical instruments using technology to give extra power to intrumental performers. \n",
    "\n",
    "The first works of this type were created in the 60s in the same studios that saw the birth of early electronic music on tape (WDR - Cologne and the RAI Phonology Studio in Milan).\n",
    "\n",
    "Mainly they were pieces for solo instrument or small ensemble and magnetic tape.\n",
    "\n",
    "The magnetic tape part usually contained both processed or simply assembled acoustic instrumental sounds and/or synthesis sounds.\n",
    "\n",
    "Bruno Maderna - Musica su due dimensioni (1958) for flute, cymbal and tape - extract\n",
    "\n",
    "<audio controls src='suoni/maderna.mp3'></audio>\n",
    "\n",
    "Karlheinz Stockhausen - Kontakte (1958-60) for Piano, percussion and 4 channels tape - extract\n",
    "\n",
    "<audio controls src='suoni/konta.mp3'></audio>\n",
    "\n",
    "In 1964 Stockhausen began to explore the expressive potential of real-time sound transformation with the piece \"Mikrophonie I\" for tam-tam, 2 microphones, 2 filters with potentiometers.\n",
    "\n",
    "<audio controls src='suoni/mikro.mp3'></audio>\n",
    "\n",
    "\n",
    "In 1976 Luigi Nono wrote with the pianist Maurizio Pollini \"...sofferte onde serene\" for piano and magnetic tape where the magnetic tape creates a virtual piano part alter ego of the one performed live\n",
    "\n",
    "<audio controls src='suoni/sofferte.mp3'></audio>\n",
    "\n",
    "Beginning in 1975 Giuseppe Di Giugno at IRCAM in Paris began development of digital processors: 4A, 4B, 4C, and in 1981 the very powerful 4X system.\n",
    "\n",
    "The musical workstation 4X is a computer tool that enables a musician to digitally manipulate sounds in real-time. \n",
    "\n",
    "Pierre Boulez is the first to use the 4X in his work RÃ©pons (1981) for six solistes, chamber ensemble and live-electronics.\n",
    "\n",
    "<audio controls src='suoni/repons.mp3'></audio>\n",
    "\n",
    "Since the early 90s with the advent of personal computers and new software dedicated to real-time sound synthesis and processing (Max/MSP, Pure Data, SuperCollider, Chuck, etc.) up to the present day, this musical field has been explored on a vast scale both musically and technologically.\n",
    "\n",
    "The focus is on designing computer systems (sensors, signal processing, and software) that measure and interpret human expression and feeling as well as on exploring the appropriate modalities and innovative content of interactive art.\n",
    "\n",
    "Few examples.\n",
    "\n",
    "Yan Maresz - Metallics (1995) for trumpet and live electronics - extract.\n",
    "\n",
    "<audio controls src='suoni/metal.mp3'></audio>\n",
    "\n",
    "Fausto Romitelli, Trash TV Trance (2002) for electric guitar and live electronics - extract.\n",
    "\n",
    "<audio controls src='suoni/trash.mp3'></audio>\n",
    "\n",
    "Georg Hajdu, Just Her - Jester - Gesture (2010) for kalimba and live electronics - extract.\n",
    "\n",
    "<audio controls src='suoni/kali.mp3'></audio>\n",
    "\n",
    "In last years also the composer/performer body became an instrument for live processing sounds.\n",
    "\n",
    "Marco Donnarumma, Corpus Nil (2016)\n",
    "\n",
    "<center><video width=\"40%\" controls src=\"suoni/donnarumma1.mp4\"></video></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c4ca0",
   "metadata": {},
   "source": [
    "## Common topics to think about <a id=\"commontopics\"></a> \n",
    "\n",
    "- music and sound relationship between acoustic and electronic parts.\n",
    "  - musical and timbre coherence.\n",
    "  - musical and timbre contrast.\n",
    "- musical and physical gestures.\n",
    "  - strictly connected with previous point.\n",
    "  - acousmatic like approach $\\rightarrow$ no relation to the historicized instrumental timbre and to traditional instrumental techniques.\n",
    "  - evident augmented musical gestures $\\rightarrow$ clear cause-effect relationship or mickey mouse effect (usually short time).\n",
    "  - masked augmented musical gestures $\\rightarrow$ no preceptive relationship between cause and effect (usually long time).\n",
    "- direction of sounds and type of sound diffusion systems.\n",
    "  - strictly connected with previous points.\n",
    "  - front diffusion systems $\\rightarrow$ mono or stereo pop concert like.\n",
    "  - immersive systems $\\rightarrow$ acoustic fields (quadriphonic, octophonic, ambisonic, wavefield synthesis, etc.).\n",
    "  - discrete diffusion systems $\\rightarrow$ speaker as musical instrument (acousmonium, laptop orchestra, etc.). \n",
    "- timbre and visual recognition of the sound source.\n",
    "  - strictly connected with previous points.\n",
    "  - the player is on a stage and audience see it and the way he produce sounds.\n",
    "- choice between pre composed electronic parts (sound files) or live processing.\n",
    "  - first choice $\\rightarrow$ pre-composed on soundfiles.\n",
    "  - we should choose live processing only when we don't want precision in the execution and aesthetically need uncontrollable margins of variation between different executions.\n",
    "  - motivations must be musical and not tied to technological fetishes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788f8e55",
   "metadata": {},
   "source": [
    "# Composition sketches proposal <a name=\"esercizi_5\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
